{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423df358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6c6e5",
   "metadata": {},
   "source": [
    "- Data Tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76bd725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated columns: Index(['preprocessed_news', 'news', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename columns for integration\n",
    "# Load twitter dataset\n",
    "twitter_df = pd.read_csv(\"Datasets/merged_datasetA(labeled).csv\")\n",
    "\n",
    "# Drop not necessory column\n",
    "twitter_df.drop(columns=['score'], inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "twitter_df.rename(columns={\n",
    "    'preprocessed_text': 'preprocessed_news',\n",
    "    'text': 'news'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Updated columns:\", twitter_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a26fcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                news  \\\n",
      "0  Readers point to Congress, the Federal Railroa...   \n",
      "1  The president of the Association of American U...   \n",
      "2  Readers discuss family estrangement from the p...   \n",
      "3  He proposed talks with South Korea to discuss ...   \n",
      "4  It was an oddly quiet end to a season of debat...   \n",
      "\n",
      "                                   preprocessed_news sentiment  \n",
      "0  readers point to congress they federal railroa...  Positive  \n",
      "1  they president of they association of american...  Positive  \n",
      "2  readers discuss family estrangement from they ...  Positive  \n",
      "3  he proposed talks with south korea to discuss ...  Positive  \n",
      "4  it was an oddly quiet end to a season of debat...  Positive  \n",
      "281758\n"
     ]
    }
   ],
   "source": [
    "# Load news Dataset\n",
    "news_df = pd.read_csv(\"Datasets/news_cleaned_trans(2018-2024).csv\")\n",
    "\n",
    "# Merge both dataset\n",
    "combinedD_df = pd.concat([news_df, twitter_df], ignore_index=True)\n",
    "\n",
    "# Save the merged dataset \n",
    "combinedD_df.to_csv(\"Datasets\\\\news_twitt_integrated.csv\", index=False)\n",
    "\n",
    "# Display first few rows \n",
    "print(combinedD_df.head())\n",
    "print(len(combinedD_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21b16c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                news  \\\n",
      "0  Readers point to Congress, the Federal Railroa...   \n",
      "1  The president of the Association of American U...   \n",
      "2  Readers discuss family estrangement from the p...   \n",
      "3  He proposed talks with South Korea to discuss ...   \n",
      "4  It was an oddly quiet end to a season of debat...   \n",
      "\n",
      "                                   preprocessed_news sentiment  \n",
      "0  Readers point to Congress the Federal Railroad...  Positive  \n",
      "1  The president of the Association of American U...  Positive  \n",
      "2  Readers discuss family estrangement from the p...  Positive  \n",
      "3  He proposed talks with South Korea to discuss ...  Positive  \n",
      "4  It was an oddly quiet end to a season of debat...  Positive  \n",
      "281753\n"
     ]
    }
   ],
   "source": [
    "# Load news Dataset\n",
    "finnews_df = pd.read_csv(\"Datasets/news_cleaned_trans_fin(2018-2024).csv\")\n",
    "\n",
    "# Merge both dataset\n",
    "combinedDF_df = pd.concat([finnews_df, twitter_df], ignore_index=True)\n",
    "\n",
    "# Save the merged dataset \n",
    "combinedDF_df.to_csv(\"Datasets\\\\news_twitt_integrated_fin.csv\", index=False)\n",
    "\n",
    "# Display first few rows \n",
    "print(combinedDF_df.head())\n",
    "print(len(combinedDF_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afd6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text Length per Label Statistics:\n",
      "==================================================\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "|  sentiment  |  max  |  min  |  mean   |  median  |   std   |  count  |\n",
      "+=============+=======+=======+=========+==========+=========+=========+\n",
      "|  Negative   |  220  |   2   | 22.0575 |    22    | 7.10095 |  90699  |\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "|   Neutral   |  74   |   2   | 18.9041 |    17    | 8.43173 |  16406  |\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "|  Positive   |  175  |   1   | 19.8262 |    20    | 7.32224 | 174653  |\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#Descriptive Analysis (AllCase)\n",
    "def print_stats(stats_df, title):\n",
    "    print(f\"\\n{title} Statistics:\")\n",
    "    print(\"=\"*50)\n",
    "    print(stats_df.to_markdown(tablefmt=\"grid\", stralign='center', numalign='center'))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "combinedD_df[\"length\"] = combinedD_df[\"news\"].apply(lambda x: len(x.split()))\n",
    "grouped_stats = combinedD_df.groupby('sentiment')[\"length\"].agg(['max', 'min', 'mean', 'median', 'std', 'count'])\n",
    "print_stats(grouped_stats, \"Text Length per Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f53d978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text Length per Label Statistics:\n",
      "==================================================\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "|  sentiment  |  max  |  min  |  mean   |  median  |   std   |  count  |\n",
      "+=============+=======+=======+=========+==========+=========+=========+\n",
      "|  Negative   |  220  |   2   | 22.0556 |    22    | 7.10234 |  90711  |\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "|   Neutral   |  74   |   2   | 18.9041 |    17    | 8.43173 |  16406  |\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "|  Positive   |  175  |   1   | 19.8278 |    20    | 7.32106 | 174636  |\n",
      "+-------------+-------+-------+---------+----------+---------+---------+\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#Descriptive Analysis (Finbert)\n",
    "def print_stats(stats_df, title):\n",
    "    print(f\"\\n{title} Statistics:\")\n",
    "    print(\"=\"*50)\n",
    "    print(stats_df.to_markdown(tablefmt=\"grid\", stralign='center', numalign='center'))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "combinedDF_df[\"length\"] = combinedDF_df[\"news\"].apply(lambda x: len(x.split()))\n",
    "grouped_stats = combinedDF_df.groupby('sentiment')[\"length\"].agg(['max', 'min', 'mean', 'median', 'std', 'count'])\n",
    "print_stats(grouped_stats, \"Text Length per Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afe202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count each sentiment label\n",
    "sentiment_counts = combinedD_df['sentiment'].value_counts()\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values)\n",
    "plt.xlabel(\"Sentiment Label\")\n",
    "plt.ylabel(\"Number of Texts\")\n",
    "plt.title(\"Distribution of Sentiment Labels (FinBERT)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93c4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([1.0354, 5.7246, 0.5378])\n"
     ]
    }
   ],
   "source": [
    "# For FinBERT Dataset\n",
    "label2id = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "combinedDF_df[\"label_id\"] = combinedDF_df[\"sentiment\"].map(label2id)\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(list(label2id.values())),\n",
    "    y=combinedDF_df[\"label_id\"]\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "print(\"Class Weights:\", class_weights_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc009f8",
   "metadata": {},
   "source": [
    "##### **Balance after split**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce2e84",
   "metadata": {},
   "source": [
    "##### **FinBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accbbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load dataset (make sure your CSV has 'text' and 'label' columns)\n",
    "finbalance_df = pd.read_csv(\"Datasets\\\\news_twitt_integrated_fin.csv\")  # e.g., columns: text,label\n",
    "\n",
    "# Convert labels to numeric if needed\n",
    "# Example: 'positive' -> 2, 'neutral' -> 1, 'negative' -> 0\n",
    "label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "finbalance_df['sentiment'] = finbalance_df['sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e8c9e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " - Train (raw): train_finbert_raw.csv\n",
      " - Test (raw): test_finbert_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# 2. Split into train/test\n",
    "train_df, test_df = train_test_split(finbalance_df, test_size=0.2, random_state=42, stratify=finbalance_df['sentiment'])\n",
    "\n",
    "train_df = train_df.rename(columns={'sentiment': 'label'})\n",
    "test_df = test_df.rename(columns={'sentiment': 'label'})\n",
    "\n",
    "train_df.to_csv(\"Datasets/train_finbert_raw.csv\", index=False)\n",
    "test_df.to_csv(\"Datasets/test_finbert_raw.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(\" - Train (raw): train_finbert_raw.csv\")\n",
    "print(\" - Test (raw): test_finbert_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127a95f",
   "metadata": {},
   "source": [
    "##### **RandomOverSampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e98aecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resampling:\n",
      "label\n",
      "2    139708\n",
      "0     72569\n",
      "1     13125\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After ROS:\n",
      "label\n",
      "2    139708\n",
      "0    139708\n",
      "1    139708\n",
      "Name: count, dtype: int64\n",
      "✅ Balanced train set saved: train_finbert_balanced(ros).csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Resampling:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply oversampling only to train\n",
    "X_resampled, y_resampled = ros.fit_resample(\n",
    "    train_df[['preprocessed_news']],  \n",
    "    train_df['label']\n",
    ")\n",
    "\n",
    "train_balanced_df = pd.DataFrame(X_resampled)\n",
    "train_balanced_df['label'] = y_resampled\n",
    "\n",
    "print(\"\\nAfter ROS:\")\n",
    "print(train_balanced_df['label'].value_counts())\n",
    "\n",
    "# Save balanced train set\n",
    "train_balanced_df.to_csv(\"Datasets/train_finbert_balanced(ros).csv\", index=False)\n",
    "\n",
    "print(\"✅ Balanced train set saved: train_finbert_balanced(ros).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e75d9b",
   "metadata": {},
   "source": [
    "##### **RandomUnderSampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbb22648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resampling:\n",
      "label\n",
      "2    139708\n",
      "0     72569\n",
      "1     13125\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After RUS:\n",
      "label\n",
      "0    13125\n",
      "1    13125\n",
      "2    13125\n",
      "Name: count, dtype: int64\n",
      "✅ Balanced train set saved: train_finbert_balanced(rus).csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Resampling:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply oversampling only to train\n",
    "X_resampled, y_resampled = rus.fit_resample(\n",
    "    train_df[['preprocessed_news']],  \n",
    "    train_df['label']\n",
    ")\n",
    "\n",
    "train_balanced_df = pd.DataFrame(X_resampled)\n",
    "train_balanced_df['label'] = y_resampled\n",
    "\n",
    "print(\"\\nAfter RUS:\")\n",
    "print(train_balanced_df['label'].value_counts())\n",
    "\n",
    "# Save balanced train set\n",
    "train_balanced_df.to_csv(\"Datasets/train_finbert_balanced(rus).csv\", index=False)\n",
    "\n",
    "print(\"✅ Balanced train set saved: train_finbert_balanced(rus).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c14754",
   "metadata": {},
   "source": [
    "##### **For Other Classification Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "711bcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load dataset (make sure your CSV has 'text' and 'label' columns)\n",
    "allcasebalance_df = pd.read_csv(\"Datasets\\\\news_twitt_integrated.csv\")  # e.g., columns: text,label\n",
    "\n",
    "# Convert labels to numeric if needed\n",
    "# Example: 'positive' -> 2, 'neutral' -> 1, 'negative' -> 0\n",
    "label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "allcasebalance_df['sentiment'] = allcasebalance_df['sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9ce2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " - Train (raw): train_allcase_raw.csv\n",
      " - Test (raw): test_allcase_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# 2. Split into train/test\n",
    "trainAC_df, testAC_df = train_test_split(allcasebalance_df, test_size=0.2, random_state=42, stratify=allcasebalance_df['sentiment'])\n",
    "\n",
    "trainAC_df = trainAC_df.rename(columns={'sentiment': 'label'})\n",
    "testAC_df = testAC_df.rename(columns={'sentiment': 'label'})\n",
    "\n",
    "trainAC_df.to_csv(\"Datasets/train_allcase_raw.csv\", index=False)\n",
    "testAC_df.to_csv(\"Datasets/test_allcase_raw.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(\" - Train (raw): train_allcase_raw.csv\")\n",
    "print(\" - Test (raw): test_allcase_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb13a8a",
   "metadata": {},
   "source": [
    "##### **RandomOverSampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02dc684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resampling:\n",
      "label\n",
      "2    139722\n",
      "0     72559\n",
      "1     13125\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After ROS:\n",
      "label\n",
      "0    139722\n",
      "2    139722\n",
      "1    139722\n",
      "Name: count, dtype: int64\n",
      "✅ Balanced train set saved: train_allcase_balanced(ros).csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Resampling:\")\n",
    "print(trainAC_df['label'].value_counts())\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply oversampling only to train\n",
    "X_resampled, y_resampled = ros.fit_resample(\n",
    "    trainAC_df[['preprocessed_news']],  \n",
    "    trainAC_df['label']\n",
    ")\n",
    "\n",
    "trainAC_balanced_df = pd.DataFrame(X_resampled)\n",
    "trainAC_balanced_df['label'] = y_resampled\n",
    "\n",
    "print(\"\\nAfter ROS:\")\n",
    "print(trainAC_balanced_df['label'].value_counts())\n",
    "\n",
    "# Save balanced train set\n",
    "trainAC_balanced_df.to_csv(\"Datasets/train_allcase_balanced(ros).csv\", index=False)\n",
    "\n",
    "print(\"✅ Balanced train set saved: train_allcase_balanced(ros).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b77925",
   "metadata": {},
   "source": [
    "##### **RandomUnderSampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60641de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resampling:\n",
      "label\n",
      "2    139722\n",
      "0     72559\n",
      "1     13125\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After RUS:\n",
      "label\n",
      "0    13125\n",
      "1    13125\n",
      "2    13125\n",
      "Name: count, dtype: int64\n",
      "✅ Balanced train set saved: train_allcase_balanced(rus).csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Resampling:\")\n",
    "print(trainAC_df['label'].value_counts())\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply oversampling only to train\n",
    "X_resampled, y_resampled = rus.fit_resample(\n",
    "    trainAC_df[['preprocessed_news']],  \n",
    "    trainAC_df['label']\n",
    ")\n",
    "\n",
    "trainAC_balanced_df = pd.DataFrame(X_resampled)\n",
    "trainAC_balanced_df['label'] = y_resampled\n",
    "\n",
    "print(\"\\nAfter RUS:\")\n",
    "print(trainAC_balanced_df['label'].value_counts())\n",
    "\n",
    "# Save balanced train set\n",
    "trainAC_balanced_df.to_csv(\"Datasets/train_allcase_balanced(rus).csv\", index=False)\n",
    "\n",
    "print(\"✅ Balanced train set saved: train_allcase_balanced(rus).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7025771",
   "metadata": {},
   "source": [
    "##### **Back Translation and Synonym Replacement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6077e",
   "metadata": {},
   "source": [
    "##### **Google Trnslator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d98e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/281753 [00:51<235:47:02,  3.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Apply back translation with progress bar\u001b[39;00m\n\u001b[32m     28\u001b[39m tqdm.pandas()\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m gt_df[\u001b[33m'\u001b[39m\u001b[33mback_translated\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mgt_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpreprocessed_news\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mback_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mback_translation_lang\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Back Translation Complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(gt_df[[\u001b[33m'\u001b[39m\u001b[33mpreprocessed_news\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mback_translated\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m]])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\tqdm\\std.py:917\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    919\u001b[39m     t.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\pandas\\core\\series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\tqdm\\std.py:912\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    907\u001b[39m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[32m    908\u001b[39m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[32m    911\u001b[39m     t.update(n=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.total \u001b[38;5;129;01mor\u001b[39;00m t.n < t.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Apply back translation with progress bar\u001b[39;00m\n\u001b[32m     28\u001b[39m tqdm.pandas()\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m gt_df[\u001b[33m'\u001b[39m\u001b[33mback_translated\u001b[39m\u001b[33m'\u001b[39m] = gt_df[\u001b[33m'\u001b[39m\u001b[33mpreprocessed_news\u001b[39m\u001b[33m'\u001b[39m].progress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mback_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mback_translation_lang\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Back Translation Complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(gt_df[[\u001b[33m'\u001b[39m\u001b[33mpreprocessed_news\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mback_translated\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m]])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mback_translate\u001b[39m\u001b[34m(text, intermediate_lang)\u001b[39m\n\u001b[32m     17\u001b[39m time.sleep(\u001b[32m0.5\u001b[39m)  \u001b[38;5;66;03m# prevent too many rapid requests (avoid rate limit)\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Intermediate language → English\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m back_translated = \u001b[43mGoogleTranslator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43mintermediate_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m time.sleep(\u001b[32m0.5\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m back_translated\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\deep_translator\\google.py:67\u001b[39m, in \u001b[36mGoogleTranslator.translate\u001b[39m\u001b[34m(self, text, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.payload_key:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mself\u001b[39m._url_params[\u001b[38;5;28mself\u001b[39m.payload_key] = text\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_base_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_url_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproxies\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequests()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\urllib3\\response.py:1248\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1245\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\urllib3\\response.py:1167\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1168\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "gt_df = pd.read_csv(\"Datasets\\\\news_twitt_integrated_fin.csv\")\n",
    "\n",
    "back_translation_lang = 'fr'\n",
    "\n",
    "def back_translate(text, intermediate_lang='fr'):\n",
    "    try:\n",
    "        translated = GoogleTranslator(source='en', target=intermediate_lang).translate(text)\n",
    "        time.sleep(0.5)  \n",
    "\n",
    "        back_translated = GoogleTranslator(source=intermediate_lang, target='en').translate(translated)\n",
    "        time.sleep(0.5)\n",
    "        return back_translated\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return text  \n",
    "\n",
    "tqdm.pandas()\n",
    "gt_df['back_translated'] = gt_df['preprocessed_news'].progress_apply(lambda x: back_translate(x, back_translation_lang))\n",
    "\n",
    "print(\"\\n✅ Back Translation Complete!\")\n",
    "print(gt_df[['preprocessed_news', 'back_translated', 'sentiment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937294fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python_Env\\fyp_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EN→FR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FR→EN model...\n",
      "EN→FR model device: cuda:0\n",
      "FR→EN model device: cuda:0\n",
      "\n",
      "=== Current Label Distribution ===\n",
      "sentiment\n",
      "Positive    174636\n",
      "Negative     90711\n",
      "Neutral      16406\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Augmentation Plan (Samples to Generate) ===\n",
      "Label: Negative   | Needed: 83925\n",
      "Label: Neutral    | Needed: 158230\n",
      "\n",
      "🔁 Back translating 83925 samples for label: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN→FR (Negative):   8%|███                                    | 822/10491 [09:06<1:47:13,  1.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🔁 Back translating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneeded_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples for label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Step 1: EN → MID_LANG\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m mid_texts = \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampled_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43men_to_fr_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43men_to_fr_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEN→\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMID_LANG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlabel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Step 2: MID_LANG → EN\u001b[39;00m\n\u001b[32m     98\u001b[39m back_translated = translate_text(\n\u001b[32m     99\u001b[39m     mid_texts,\n\u001b[32m    100\u001b[39m     fr_to_en_tokenizer,\n\u001b[32m    101\u001b[39m     fr_to_en_model,\n\u001b[32m    102\u001b[39m     desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMID_LANG.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m→EN (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    103\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mtranslate_text\u001b[39m\u001b[34m(texts, tokenizer, model, max_length, batch_size, desc)\u001b[39m\n\u001b[32m     46\u001b[39m encoded = tokenizer(batch, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, max_length=max_length).to(device)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     generated = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m out_texts = tokenizer.batch_decode(generated, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     50\u001b[39m translated.extend(out_texts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\generation\\utils.py:3265\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3262\u001b[39m flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   3263\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3265\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3267\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3268\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3269\u001b[39m     model_outputs,\n\u001b[32m   3270\u001b[39m     model_kwargs,\n\u001b[32m   3271\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3272\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:1522\u001b[39m, in \u001b[36mMarianMTModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1517\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1518\u001b[39m         decoder_input_ids = shift_tokens_right(\n\u001b[32m   1519\u001b[39m             labels, \u001b[38;5;28mself\u001b[39m.config.pad_token_id, \u001b[38;5;28mself\u001b[39m.config.decoder_start_token_id\n\u001b[32m   1520\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1522\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1532\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1540\u001b[39m lm_logits = \u001b[38;5;28mself\u001b[39m.lm_head(outputs[\u001b[32m0\u001b[39m]) + \u001b[38;5;28mself\u001b[39m.final_logits_bias\n\u001b[32m   1542\u001b[39m masked_lm_loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:1278\u001b[39m, in \u001b[36mMarianModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1271\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1272\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1273\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1274\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1275\u001b[39m     )\n\u001b[32m   1277\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_values, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1278\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1288\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1289\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1292\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:1069\u001b[39m, in \u001b[36mMarianDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1066\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dropout_probability < \u001b[38;5;28mself\u001b[39m.layerdrop:\n\u001b[32m   1067\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1083\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:435\u001b[39m, in \u001b[36mMarianDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_values, output_attentions, use_cache, cache_position)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    433\u001b[39m     residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     hidden_states, cross_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    445\u001b[39m     hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:217\u001b[39m, in \u001b[36mMarianAttention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, past_key_values, attention_mask, layer_head_mask, output_attentions, cache_position, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m kv_input_shape = (bsz, src_len, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.head_dim)\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# get query proj\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m query_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m.view(*q_input_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    219\u001b[39m is_updated = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python_Env\\fyp_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "\n",
    "btsr_df = pd.read_csv(\"Datasets\\\\news_twitt_integrated_fin.csv\")\n",
    "\n",
    "SRC_LANG = \"en\"\n",
    "MID_LANG = \"fr\"   # You can switch to 'de', 'es', 'zh', etc.\n",
    "\n",
    "en_to_fr_model_name = f\"Helsinki-NLP/opus-mt-{SRC_LANG}-{MID_LANG}\"\n",
    "fr_to_en_model_name = f\"Helsinki-NLP/opus-mt-{MID_LANG}-{SRC_LANG}\"\n",
    "\n",
    "print(\"Loading EN→FR model...\")\n",
    "en_to_fr_tokenizer = MarianTokenizer.from_pretrained(en_to_fr_model_name)\n",
    "en_to_fr_model = MarianMTModel.from_pretrained(en_to_fr_model_name)\n",
    "\n",
    "print(\"Loading FR→EN model...\")\n",
    "fr_to_en_tokenizer = MarianTokenizer.from_pretrained(fr_to_en_model_name)\n",
    "fr_to_en_model = MarianMTModel.from_pretrained(fr_to_en_model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "en_to_fr_model.to(device)\n",
    "fr_to_en_model.to(device)\n",
    "print(\"EN→FR model device:\", next(en_to_fr_model.parameters()).device)\n",
    "print(\"FR→EN model device:\", next(fr_to_en_model.parameters()).device)\n",
    "\n",
    "def translate_text(texts, tokenizer, model, max_length=512, batch_size=8, desc=\"Translating\"):\n",
    "    translated = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=desc, ncols=100):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        encoded = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(**encoded)\n",
    "        out_texts = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "        translated.extend(out_texts)\n",
    "    return translated\n",
    "\n",
    "label_counts = btsr_df['sentiment'].value_counts()\n",
    "max_count = label_counts.max()\n",
    "\n",
    "print(\"\\n=== Current Label Distribution ===\")\n",
    "print(label_counts)\n",
    "\n",
    "augmentation_plan = {}\n",
    "for label, count in label_counts.items():\n",
    "    if count < max_count:\n",
    "        needed = max_count - count\n",
    "        augmentation_plan[label] = needed\n",
    "\n",
    "print(\"\\n=== Augmentation Plan (Samples to Generate) ===\")\n",
    "for label, needed in augmentation_plan.items():\n",
    "    print(f\"Label: {label:10} | Needed: {needed}\")\n",
    "\n",
    "augmented_rows = []\n",
    "\n",
    "for label, needed_samples in augmentation_plan.items():\n",
    "    subset = btsr_df[btsr_df['sentiment'] == label]\n",
    "\n",
    "    sampled_texts = subset['preprocessed_news'].sample(\n",
    "        n=needed_samples,\n",
    "        replace=True,\n",
    "        random_state=42\n",
    "    ).tolist()\n",
    "\n",
    "    print(f\"\\n🔁 Back translating {needed_samples} samples for label: {label}\")\n",
    "\n",
    "    mid_texts = translate_text(\n",
    "        sampled_texts,\n",
    "        en_to_fr_tokenizer,\n",
    "        en_to_fr_model,\n",
    "        desc=f\"EN→{MID_LANG.upper()} ({label})\"\n",
    "    )\n",
    "\n",
    "    back_translated = translate_text(\n",
    "        mid_texts,\n",
    "        fr_to_en_tokenizer,\n",
    "        fr_to_en_model,\n",
    "        desc=f\"{MID_LANG.upper()}→EN ({label})\"\n",
    "    )\n",
    "\n",
    "    augmented_rows.extend([\n",
    "        {'preprocessed_news': bt, 'sentiment': label} for bt in back_translated\n",
    "    ])\n",
    "\n",
    "\n",
    "aug_df = pd.DataFrame(augmented_rows)\n",
    "final_df = pd.concat([btsr_df, aug_df], ignore_index=True)\n",
    "\n",
    "# Check new label distribution\n",
    "print(\"\\n=== New Label Distribution (After Augmentation) ===\")\n",
    "print(final_df['sentiment'].value_counts())\n",
    "\n",
    "\n",
    "final_df.to_csv(\"Datasets\\\\news_twitt_integrated_fin(BTSR).csv\", index=False)\n",
    "print(\"\\n✅ Balanced dataset saved as 'news_twitt_integrated_fin(BTSR).csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
